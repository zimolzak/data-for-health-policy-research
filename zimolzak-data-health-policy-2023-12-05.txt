---
title: Electronic Health Record Data for Health Policy Research
author: Andrew Zimolzak, MD, MMSc
date: December 5, 2023
theme: Goettingen
fonttheme: structurebold
colortheme: whale
aspectratio: 169
---



# Intro, & research *about* policy

## About me

| Research                              | Clinical |
|:---------------------------------------|:------------------------------|
|                                          |  Internal medicine residency |
| MMSc biomedical informatics                  | Outpatient urgent care |
| Veterans Affairs Boston:  | Hospitalist |
| VA Health services research | Hospitalist |

What is *Clinical research informatics?*

- I make various clinical research studies "go," using existing data
- "Phenotyping" using electronic health record (EHR) data




## A detailed reference about secondary use

![](book.jpg){ height=50% }

MIT Critical Data. *Secondary Analysis of Electronic Health Records.*
Springer Cham, 2016.

[Click for free access](https://link.springer.com/book/10.1007/978-3-319-43742-2)




## How I (an informatics person) look at these studies

- database type
- whose data?
- "pre" methods (how carefully did they do "phenotyping"?)
- study type (broadly)
- ...and oh yes, the details of "real" analysis methods and results






# 1: Medicaid expansion affects VA utilizatiton[^pom]

[^pom]: O'Mahen PN, Petersen LA. Effects of State-level Medicaid Expansion on
Veterans Health Administration Dual Enrollment and Utilization:
Potential Implications for Future Coverage Expansions. *Med Care.*
2020;58(6):526--533. <https://pubmed.ncbi.nlm.nih.gov/32205790/>




## Methods

### Data

- EHR (plus)
- VA & Medicaid, 1999--2006
- pre methods tk

### Analytic

- difference-in-difference analysis
- exposure: Medicaid expansion (NY and AZ in 2001)
- endpoints: dual enrollment, hospital admissions, ED visits




## Results

- dual enroll tk
- hospital admit tk
- ED visits tk

### Bottom line

Great example of a study that measured the **effect of a policy** on
several outcome variables derived from the EHR.




# 2: Measuring delayed opioid dispensing[^kao]

[^kao]: Chua KP, Waljee JF, Smith MA, Bahl S, Nalliah RP, Brummett CM.
Estimation of the Prevalence of Delayed Dispensing Among Opioid
Prescriptions From US Surgeons and Dentists. *JAMA Netw Open.*
2022;5(5):e2214311. <https://pubmed.ncbi.nlm.nih.gov/35622363/>




## Methods

Delayed dispensing:
: Dispensing > 30 days after writing: possibly used for unintended reasons/dates.

### Data

- deidentified prescription writing, fill date, *etc.* (not EHR)
- IQVIA Formulary Impact Analyzer ($\approx$ 63% of US Rx), 2014--2019
- legal databases too (NABPLAW, Westlaw Edge)
- pre methods tk

### Analytic

- descriptive
- difference-in-difference analysis
- exposure: Change in Minnesota law, July 2019
- endpoint: % of delayed opioid dispensing




## Technical

$\mathbb{E}(Y_{ist}) = \beta_1 \mathsf{State}_s + \beta_2
\mathsf{Month}_t + \beta_3 \mathsf{Minnesota}_{ist} \mathsf{Post}_{ist}$

tk: move me to end?



## Effect of change in policy

![Minnesota $0.55 \to 0.13$%, *vs.* controls $1.12 \to 0.97$](kao-graph.jpg)




## Results

- endpoint tk

### Bottom line

tk




# 3: An electronic measure of diagnostic quality[^drm]

[^drm]: Murphy DR, Zimolzak AJ, Upadhyay DK, *et al.* Developing electronic clinical quality measures to assess the cancer diagnostic process. *J Am Med Inform Assoc.* 2023;30(9):1526--1531. <https://pubmed.ncbi.nlm.nih.gov/37257883/>



## Methods

### Data

- database type tk
- whose data tk
- pre methods tk

### Analytic

- tk
- exposure: tk
- endpoint: 





## Results

- endpoint tk

### Bottom line

tk





# 4: Detecting wrong-side imaging tests[^she]

[^she]: Sheehan SE, Safdar N, Singh H, *et al.* Detection and
Remediation of Misidentification Errors in Radiology Examination
Ordering. *Appl Clin Inform.* 2020;11(1):7--87.
<https://pubmed.ncbi.nlm.nih.gov/31995835/>



## Methods

### Data

- database type tk
- whose data tk
- pre methods tk

### Analytic

- tk
- exposure: tk
- endpoint: 



## Results

- endpoint tk

### Bottom line

tk



## Results quote

> These findings raise questions about the reliability of staff
> adherence to departmental guidelines in faithful checklist
> performance and spreadsheet completion, and again raise suspicion of
> potential workarounds.

- Consider: not "imperfect staff" but "imperfect policy?"
- Or, avoid "blame game" altogether


# Summary and advice




## Summary of studies I presented

### Medicaid expansion

**Data:** EHR + Medicaid. **Question:** state policy $\to$ utilization.

### Delayed dispensing

**Data:** Prescribing + legal. **Question:** state policy $\to$ practice pattern.

### Electronic quality measure

**Data:** EHR. **Question:** measure development and validation.
*But:* novel measure $\to$ a policy incentivizing improvements? Or:
new policy $\to$ effect on this measure?

### Sheehan

**Data:** Internal spreadsheet + EHR. **Question:**  *local* policy $\to$ its
intended effect. (Measuring staff adherence to an *existing
departmental* policy)




## VA data overview[^fihn]

- 20 million individuals
- 2 billion outpatient visits
- etc tk

[^fihn]: Fihn *et al. Health Affairs* 33:1203 (2014)




## "Just search" for your data

sodium[^nate]

[^nate]: Fillmore, N., *et al.* Interactive Machine Learning for
Laboratory Data Integration. *Stud Health Technol* 264, 133--137.




## "Just do"

A1c




## Statins

confound by indication



## Statin

slide 2+ on this




## It takes a long time

- datathon example
- know that datathon exists
- Amgen example of phenotyping
- actual manual chart review is a thing. Hard work; get *different aspects*


## what's in EHR data

- list

Probably need assistance



## EHR data $\ne$ EHR data

### Data just among Houston BCM affiliates

- Baylor St.\ Luke's $\subset$ St.\ Luke's Health $\subset$ CommonSpirit
- Baylor Clinic
- Harris Health
- TCH
- DeBakey VA Med.\ Center $\subset$ VA

### The problems

- VA $\ne$ Epic
- $\mathsf{Epic}_1 \ne \mathsf{Epic}_2$
- $\mathsf{VA}_1 \ne \mathsf{VA}_2$ (yes, really)






# How policy *affects research*

## actual hipaa

- safe harbor



## "Fancy anonymization"

- Dwork



## Getting access



## Examples of deident EHR

- mimic


## Research data/code sharing

- sadly uncommon
- journals have policies
- NIH has policies




# A bit about "AI"

## definition

- super broad
- we've had AI for decades

## stats vs ml

hastie

## choice quotes

- "unfortunate trend"
- "false dichotomy between statistics and ML"

> dichotomy enables

## Maarten 3/16

> call it prediction model

## Maarten 6/21

> the statistics vs machine




## Chat bots

> Sutskever [chief OpenAI scientist] was shocked at the reaction to ChatGPT.  He noticed three main phenomena which disturbed him greatly

> 1. A number of practising psychiatrists believed that ChatGPT could grow into an almost completely automatic form of psychotherapy.

> 2. Users very quickly became emotionally involved---Sutskever's secretary demanded to be left alone with the program, for example.

> 3. Some people believed that the program demonstrated a general solution to the problem of computer understanding of natural language.




## Whoops, that was 1976, not 2022![^eliza]

> Weizenbaum was shocked at the reaction to ELIZA.  He noticed three main phenomena which disturbed him greatly
> 1. A number of practising psychiatrists believed that ELIZA could grow into an almost completely automatic form of psychotherapy.
> 2. Users very quickly became emotionally involvedâ€”Weizenbaum's secretary demanded to be left alone with the program, for example.
> 3. Some people believed that the program demonstrated a general solution to the problem of computer understanding of natural language.

[^eliza]: Weizenbaum, J. 1976. *Computer Power & Human Reason.* W.H. Freeman & Co.












## Contact

tk

Slides on github

CCommons







## TK

- aspect ratio
- include benefits of EHR
